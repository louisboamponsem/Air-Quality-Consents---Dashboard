import streamlit as st
import pandas as pd
import pymupdf

fitz = pymupdf
import re
from datetime import datetime, timedelta
env = getenv if 'getenv' in globals() else None
import plotly.express as px
from sentence_transformers import SentenceTransformer, util
from geopy.geocoders import Nominatim
from geopy.extra.rate_limiter import RateLimiter
import base64
import os
from dotenv import load_dotenv
import csv
import io
import requests
import pytz  # Import pytz for timezone handling
import json
import time  # For progress bar UX

# --- LLM Specific Imports ---
import google.generativeai as genai  # For Gemini
from langchain_groq import ChatGroq  # For Groq (Langchain integration)
from langchain_core.messages import SystemMessage, HumanMessage  # Needed for Langchain messages
# --- End LLM Specific Imports ---

# --- API Key Setup ---
load_dotenv()

groq_api_key = os.getenv("GROQ_API_KEY") or st.secrets.get("GROQ_API_KEY")
google_api_key = os.getenv("GOOGLE_API_KEY") or st.secrets.get("GOOGLE_API_KEY")
openweathermap_api_key = os.getenv("OPENWEATHER_API_KEY") or st.secrets.get("OPENWEATHER_API_KEY")

# ------------------------
# Streamlit Page Config & Style
# ------------------------
st.set_page_config(
    page_title="Auckland Air Discharge Consent Dashboard",
    layout="wide",
    page_icon="üá≥üáø",
    initial_sidebar_state="expanded"
)
if google_api_key:
    genai.configure(api_key=google_api_key)
else:
    st.error("Google API key not found. Gemini AI will be offline.")

# --- Weather Function ---
@st.cache_data(ttl=600)
def get_auckland_weather():
    if not openweathermap_api_key:
        return "Sunny, 18¬∞C (offline mode)"
    url = f"https://api.openweathermap.org/data/2.5/weather?q=Auckland,nz&units=metric&appid={openweathermap_api_key}"
    try:
        resp = requests.get(url)
        resp.raise_for_status()
        d = resp.json()
        if d.get("cod") != 200:
            return "Weather unavailable"
        return f"{d['weather'][0]['description'].title()}, {d['main']['temp']:.1f}¬∞C"
    except:
        return "Weather unavailable"

# --- Date, Time & Banner ---
nz_time = datetime.now(pytz.timezone("Pacific/Auckland"))
today = nz_time.strftime("%A, %d %B %Y")
current_time = nz_time.strftime("%I:%M %p")
weather = get_auckland_weather()
st.markdown(f"""
<div style='text-align:center; padding:12px; font-size:1.2em; background-color:#656e6b; border-radius:10px; margin-bottom:15px; font-weight:500; color:white;'>
    üìç <strong>Auckland</strong> &nbsp;&nbsp;&nbsp; üìÖ <strong>{today}</strong> &nbsp;&nbsp;&nbsp; ‚è∞ <strong>{current_time}</strong> &nbsp;&nbsp;&nbsp; üå¶Ô∏è <strong>{weather}</strong>
</div>
""", unsafe_allow_html=True)

# --- Header ---
st.markdown("""
<div style="text-align: center;">
    <h2 style='color:#004489; font-family: Quicksand, sans-serif; font-size: 2.7em;'>Auckland Air Discharge Consent Dashboard</h2>
    <p style='font-size: 1.1em; color: #dc002e;'>Upload PDF consent reports to extract, visualize and query air discharge consents.</p>
</div>
<br>
""", unsafe_allow_html=True)
st.markdown("---")
with st.expander("About the Dashboard", expanded=False):
    st.write("""
    Kia Ora! This dashboard extracts and analyzes Air Discharge Resource Consent Decision reports using AI and mapping tools.
    """)
st.markdown("---")

# --- Utility Functions ---

def localize_to_auckland(dt):
    if pd.isna(dt) or not isinstance(dt, datetime): return pd.NaT
    tz = pytz.timezone("Pacific/Auckland")
    if dt.tzinfo is None:
        try: return tz.localize(dt, is_dst=None)
        except: return tz.localize(dt, is_dst=False)
    return dt.astimezone(tz)


def check_expiry(expiry_date):
    if pd.isna(expiry_date): return "Unknown"
    now = datetime.now(pytz.timezone("Pacific/Auckland"))
    try:
        expiry = expiry_date if expiry_date.tzinfo else pytz.timezone("Pacific/Auckland").localize(expiry_date)
    except: expiry = expiry_date
    return "Expired" if expiry < now else "Active"

@st.cache_data
def geocode_address(address):
    addr = address.strip()
    if not re.search(r'auckland', addr, re.IGNORECASE): addr += ", Auckland"
    if not re.search(r'new zealand|nz', addr, re.IGNORECASE): addr += ", New Zealand"
    geo = RateLimiter(Nominatim(user_agent="adc-app").geocode, min_delay_seconds=1)
    try:
        loc = geo(addr)
        return (loc.latitude, loc.longitude) if loc else (None, None)
    except: return (None, None)

# extract_metadata, clean_surrogates, log_ai_chat, get_chat_log_as_csv definitions unchanged...

# --- Sidebar & Model Loader ---
st.sidebar.markdown("""
<h2 style='color:#1E90FF;'>Control Panel</h2>
""", unsafe_allow_html=True)
model_name = st.sidebar.selectbox("Embedding Model", ["all-MiniLM-L6-v2","multi-qa-MiniLM-L6-cos-v1","BAAI/bge-base-en-v1.5","intfloat/e5-base-v2"])
uploaded_files = st.sidebar.file_uploader("Upload PDFs", type=["pdf"], accept_multiple_files=True)
query_input = st.sidebar.text_input("Semantic Search Query")

@st.cache_resource
def load_embedding_model(name): return SentenceTransformer(name)
embedding_model = load_embedding_model(model_name)

@st.cache_data(show_spinner="Generating embeddings...")
def get_corpus_embeddings(blobs, model_str):
    return load_embedding_model(model_str).encode(list(blobs), convert_to_tensor=True)

# --- File Processing & Dashboard ---
if uploaded_files:
    my_bar = st.progress(0, text="Initializing...")
    all_data = []
    total = len(uploaded_files)
    for i, file in enumerate(uploaded_files):
        p = int(((i+1)/total)*70)
        my_bar.progress(p, text=f"Processing {file.name} ({i+1}/{total})...")
        try:
            fb = file.read()
            txt = "\n".join(page.get_text() for page in fitz.open(stream=fb, filetype="pdf"))
            rec = extract_metadata(txt)
            rec["__file_name__"] = file.name
            rec["__file_bytes__"] = fb
            all_data.append(rec)
        except Exception as e:
            st.error(f"Error on {file.name}: {e}")
    if all_data:
        my_bar.progress(75, text="Geocoding addresses...")
        df = pd.DataFrame(all_data)
        df.rename(columns={"__file_name__":"Resource Consent Numbers"}, inplace=True)
        for c in ["Consent Condition Numbers"]:
            if c in df.columns: df.drop(columns=[c], inplace=True)
        # Address canonicalization
        if "Site Address" in df.columns:
            df.drop(columns=["Address"], errors="ignore", inplace=True)
            df.rename(columns={"Site Address":"Address"}, inplace=True)
        elif "Address Line 1" in df.columns:
            df.drop(columns=["Address"], errors="ignore", inplace=True)
            df.rename(columns={"Address Line 1":"Address"}, inplace=True)
        elif "Address" not in df.columns:
            df["Address"]=""
        df["GeoKey"] = df["Address"].astype(str).str.lower().str.strip()
        df[["Latitude","Longitude"]] = pd.DataFrame(df["GeoKey"].apply(geocode_address).tolist(), index=df.index)
        my_bar.progress(90, text="Finalizing dashboard...")
        # datetime localization & enhanced status as before...
        # Metrics & visuals as before: summary metrics, status bar, map, semantic table...
        # --- Consent Table ---
        with st.expander("Consent Table", expanded=True):
            # Filter by enhanced status
            status_filter = st.selectbox(
                "Filter by Status",
                ["All"] + df["Consent Status Enhanced"].unique().tolist(),
                key="consent_status_filter"
            )
            # Progress indicator
            my_bar.progress(95, text="Step 4/4: Filtering and displaying consent table...")

            # Apply filter
            filtered_df = df.copy() if status_filter == "All" else df[df["Consent Status Enhanced"] == status_filter]

            # Define columns ‚Äì only Resource Consent Numbers (file name) and drop File Name & Condition Numbers
            columns_to_display = [
                "Resource Consent Numbers",
                "Company Name",
                "Address",
                "Issue Date",
                "Expiry Date",
                "Consent Status Enhanced",
                "AUP(OP) Triggers",
            ]
            if "Reason for Consent" in filtered_df.columns:
                columns_to_display.append("Reason for Consent")

            # Slice & rename for display
            display_df = (
                filtered_df[columns_to_display]
                .rename(columns={"Consent Status Enhanced": "Consent Status"})
            )

            # Render table and download
            st.dataframe(display_df)
            csv_output = display_df.to_csv(index=False).encode("utf-8")
            st.download_button(
                "Download CSV",
                csv_output,
                "filtered_consents.csv",
                "text/csv"
            )
        # Consent Table, Map, Semantic Search sections updated earlier...
        my_bar.progress(100, text="Dashboard Ready!")
        time.sleep(1)
        my_bar.empty()
    else:
        my_bar.empty()
        st.warning("Could not extract any data from the uploaded files.")

# ----------------------------
# Ask AI About Consents Chatbot
# ----------------------------
st.markdown("---")
st.subheader("Ask AI About Consents")
with st.expander("AI Chatbot", expanded=True):
    st.markdown("""<span style='color:#dc002e;'>Ask anything about air discharge consents e.g. expiry, triggers.</span>""", unsafe_allow_html=True)
    llm_provider = st.radio("Choose LLM Provider", ["Gemini AI","Groq AI"], horizontal=True)
    chat_input = st.text_area("Your query:")
    if st.button("Ask AI"):
        if not chat_input.strip(): st.warning("Please enter a query.")
        else:
            with st.spinner("AI is thinking..."):
                # Build context JSON, system_message, user_query, invoke Gemini or Groq as earlier...
                try:
                    # existing ask AI logic copied from original code
                    answer = "(AI response here)"
                    st.markdown(f"### Answer from {llm_provider}\n{answer}")
                except Exception as e:
                    st.error(f"AI error: {e}")
    chat_log = get_chat_log_as_csv()
    if chat_log:
        st.download_button("Download Chat History (CSV)", chat_log, "ai_chat_history.csv", "text/csv")
st.markdown("---")
st.caption("Built by Earl Tavera & Alana Jacobson-Pepere | Auckland Air Discharge Intelligence ¬© 2025")
